{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noise as target\n",
    "A keras implementation of the [Unsupervised learning by predicting noise](https://arxiv.org/abs/1704.05310) paper  \n",
    "  \n",
    "Here's an analysis of the paper I rather enjoyed. [link](http://www.inference.vc/unsupervised-learning-by-predicting-noise-an-information-maximization-view-2/)  \n",
    "  \n",
    "This is an extraction and reformatting of the implementation my team and I made as part of the \"[Mozgalo](https://www.estudent.hr/category/natjecanja/mozgalo/)\" competition.  \n",
    "  \n",
    "I have the [celebA](http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html) dataset on hand, and it's a decently big and publicly available dataset unlike mozgalo so this demo uses it.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.pooling import MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "from itertools import cycle, islice\n",
    "\n",
    "from utils import rand_unit_sphere, shuffle_assigned_noises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_shape = (224,224)\n",
    "batch_size = 64\n",
    "n_features = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model\n",
    "This is a [darknet](https://pjreddie.com/darknet/imagenet/) model.  \n",
    "You can use whatever you wish. One of the things I find so nice about this method is that the models are interchangeable with standard classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convolutional_block(inp, filters):\n",
    "    x = Conv2D(filters=filters, kernel_size=3, strides=(1,1), padding='same', use_bias=False)(inp)\n",
    "    x = BatchNormalization()(x) # is this it?\n",
    "    x = LeakyReLU()(x)\n",
    "    x = MaxPooling2D(pool_size=(2,2), strides=2)(x)\n",
    "    return x\n",
    "\n",
    "c = 1  # we train on b&w images, as the paper suggests, to make the training objective harder \n",
    "\n",
    "\n",
    "input_img = Input(shape=(*image_shape, c))\n",
    "\n",
    "x = convolutional_block(input_img, 16)\n",
    "\n",
    "x = convolutional_block(x, 32)\n",
    "\n",
    "x = convolutional_block(x, 64)\n",
    "\n",
    "x = convolutional_block(x, 128)\n",
    "\n",
    "x = convolutional_block(x, 256)\n",
    "\n",
    "x = convolutional_block(x, 512)\n",
    "\n",
    "x = convolutional_block(x, 1024)\n",
    "\n",
    "x = Conv2D(filters=n_features, kernel_size=1, strides=(1,1), padding='same', use_bias=False)(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "model = Model(inputs=input_img, outputs=x)\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='adam')\n",
    "\n",
    "# print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### or if you prefer, load a trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('../models/something')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def noises_from_keys(noises, keys):\n",
    "    '''\n",
    "    returns the assigned noise vectors for a batch of images\n",
    "    '''\n",
    "    # keys = list(keys)\n",
    "    n = np.empty(shape=(len(keys), n_features), dtype='float64')\n",
    "    for i in range(len(keys)):\n",
    "        n[i] = noises[keys[i]]\n",
    "        \n",
    "    return n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 99 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "            rotation_range=40,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            rescale=1./255,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            fill_mode='nearest')\n",
    "\n",
    "datagen = datagen.flow_from_directory(\n",
    "    '../data/img_align_celeba_sample/',\n",
    "    target_size=image_shape,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    shuffle=False,\n",
    "    color_mode='grayscale'\n",
    "    )\n",
    "\n",
    "n_images = datagen.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datagen_wrapper(datagen, noises, model):\n",
    "    filename_iter = cycle(datagen.filenames)\n",
    "    \n",
    "    while True:\n",
    "        next_imgs = datagen.__next__()\n",
    "        this_batch_size = len(next_imgs) # last batch in epoch may have fewer elements\n",
    "        next_filenames = list(islice(filename_iter, this_batch_size))\n",
    "\n",
    "        next_noises = noises_from_keys(noises, next_filenames)\n",
    "        \n",
    "        # do forward pass on batch - features\n",
    "        losses = np.empty(shape=(this_batch_size, this_batch_size), dtype='float64')\n",
    "        features = model.predict_on_batch(next_imgs)\n",
    "        \n",
    "        # calculate l2 loss between all...\n",
    "        # noises randomly assigned and features generated by the network\n",
    "        for b in range(this_batch_size):\n",
    "            fts = np.repeat(np.expand_dims(features[b], axis = 0), this_batch_size, axis=0)\n",
    "            l2 = np.linalg.norm(fts - next_noises, axis=1)\n",
    "            losses[b] = l2\n",
    "            \n",
    "        # rearrange noises such that the total loss is minimal (hungarian algorithm)\n",
    "        row_ind, col_ind = linear_sum_assignment(losses)\n",
    "        for r, c in zip(row_ind, col_ind):\n",
    "            noises[next_filenames[r]] = next_noises[c]\n",
    "        \n",
    "        # get the same noises as before but in new assignment order\n",
    "        next_noises = noises_from_keys(next_filenames)\n",
    "        \n",
    "        yield next_imgs, next_noises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unit_sphere_noises = rand_unit_sphere(n_images, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assigned_noises = {}\n",
    "\n",
    "for fn, ft in zip(datagen.filenames, unit_sphere_noises):\n",
    "    assigned_noises[fn] = ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen = datagen_wrapper(datagen, assigned_noises, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 224, 224, 1)\n",
      "(64, 1000)\n"
     ]
    }
   ],
   "source": [
    "x, y = gen.__next__()\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "#gen_wrapper(gen, filenames, noises)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShuffleNoises(Callback):\n",
    "    \n",
    "    def __init__(self, noises, epochs_per_shuffle=3):\n",
    "        self.noises = noises\n",
    "        self.epochs_per_shuffle = epochs_per_shuffle\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        print(epoch)\n",
    "        if epoch % self.epochs_per_shuffle == 0:\n",
    "            shuffle_assigned_noises(noises)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs_per_shuffle=3\n",
    "\n",
    "# base name of model save file - based on training start time\n",
    "save_dir = '../models/'\n",
    "folder_name = time.strftime(\"%Y-%m-%d-%H-%M/\", time.gmtime())\n",
    "save_dir = save_dir + folder_name\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "epoch = 1\n",
    "while True:\n",
    "    print('Running epoch:', epoch)\n",
    "    for b in range(3):\n",
    "        for i in tqdm(n_images / batch_size))):\n",
    "            \n",
    "            \n",
    "            # do a backprop pass with the newly arranged features\n",
    "            model.train_on_batch(images, n)\n",
    "            \n",
    "        # every epoch save model\n",
    "        model.save(save_dir  + str(epoch) + '.model')\n",
    "        epoch += 1\n",
    "            \n",
    "    # every cca 3 epochs shuffle noises\n",
    "    noises = shuffle_noises(noises)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
